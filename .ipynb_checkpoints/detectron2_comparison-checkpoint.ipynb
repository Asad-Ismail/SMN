{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bd7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb23e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segmentation_dataset(f_p,label_names=None):\n",
    "    \"\"\"\"\n",
    "    Returns:\n",
    "        [dict]: Dictionary of list with names \n",
    "    \"\"\"\n",
    "    data=load_json(f_p)\n",
    "    cat_map={}\n",
    "    for cat in data[\"categories\"]:\n",
    "        if cat[\"name\"] in label_names:\n",
    "            cat_map[cat['id']]=cat[\"name\"] \n",
    "    image_map={}\n",
    "    for cat in data[\"images\"]:\n",
    "        image_map[cat['id']]=cat[\"file_name\"] \n",
    "    annos={}\n",
    "    for d in data[\"annotations\"]:\n",
    "        tmp=[]\n",
    "        seg=d[\"segmentation\"][0]\n",
    "        for i in range(0,len(seg)-1,2):\n",
    "            tmp.append([seg[i],seg[i+1]]) \n",
    "        if image_map[d[\"image_id\"]] not in annos:\n",
    "            annos[image_map[d[\"image_id\"]]]=[{\"class_id\":cat_map[d[\"category_id\"]],\"annotation\":tmp}]\n",
    "        else:\n",
    "            annos[image_map[d[\"image_id\"]]].append({\"class_id\":cat_map[d[\"category_id\"]],\"annotation\":tmp})\n",
    "    return annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/home/asad/projs/SMN/data/cucumber\"\n",
    "ann=load_segmentation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1047e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
    "# from detectron2.data.datasets import register_coco_instances\n",
    "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
    "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
    "\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_veg_dicts(img_dir): \n",
    "    \n",
    "    json_files = [\n",
    "            json_file\n",
    "            for json_file in os.listdir(img_dir)\n",
    "            if json_file.endswith(\".json\")\n",
    "    ]\n",
    "    dataset_dicts = []\n",
    "    for idx, json_file in tqdm(enumerate(json_files),total=len(json_files)):\n",
    "        for ext in self.extensions:\n",
    "            filename = json_file.split(\".\")[0] + ext\n",
    "            c_fname = os.path.join(img_dir, filename)\n",
    "            img = cv2.imread(c_fname)\n",
    "            if img is not None:\n",
    "                break\n",
    "        if img is None:\n",
    "            print(f\"Image Not Found for {json_file}\")\n",
    "            raise (f\"Image Not Found for {json_file}\")\n",
    "        #print(f\"Processing json {json_file}\")\n",
    "        loaded=load_segmentation_dataset(os.path.join(img_dir, json_file))\n",
    "        record = {}\n",
    "        height, width = img.shape[:2]\n",
    "        record[\"file_name\"] = c_fname\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        annos = imgs_anns[\"shapes\"]\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            px = [x for x, y in anno]\n",
    "            py = [y for x, y in anno]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        #print(f\"Processed images {idx}\")\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "\n",
    "    return dataset_dicts\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n",
    "    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
    "balloon_metadata = MetadataCatalog.get(\"balloon_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
